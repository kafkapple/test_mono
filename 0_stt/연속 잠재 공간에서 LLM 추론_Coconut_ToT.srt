1
00:00:00,000 --> 00:00:05,839
안녕하세요. 여기는 바이트비트 마인드 캐스트. 흥미로운 AI, 뇌과학, 심리학

2
00:00:05,839 --> 00:00:11,359
논문에 쉽고 재미있게 파이처보는 시간입니다. AI가 단순히 정보를 찾는

3
00:00:11,359 --> 00:00:15,800
걸 넘어서 정말 생각이라는 걸 할 수 있을까요.

4
00:00:15,800 --> 00:00:20,320
그렇죠. 요즘 AI가 복잡한 문제를 푸는 걸 보면 그런 질문이 나올

5
00:00:20,320 --> 00:00:23,160
법도 한데요. 네. 오늘 저희가 살펴볼 자르들이

6
00:00:23,160 --> 00:00:27,960
바로 그 AI의 출원 방식에 대한 아주 흥미로운 연구들입니다.

7
00:00:27,960 --> 00:00:32,880
반갑습니다. 사람이 여러 방식으로 생각하는 것처럼 AI도 기술이 점점

8
00:00:32,880 --> 00:00:36,480
발전하고 있어요. 대표적인 세 가지를 짚어볼 건데요.

9
00:00:36,480 --> 00:00:42,520
연세적 사고 코오티 이라고 하죠. 그리고 생각의 틀이 TOT. 네. 그리고

10
00:00:42,520 --> 00:00:46,799
오늘 특히 좀 더 주목해볼 코코넛이라는 새로운 방식까지요.

11
00:00:46,799 --> 00:00:51,359
네. 코코넛. 이름이 재밌네요. 이 세 가지를 통해 AI 출원이 어떻게

12
00:00:51,359 --> 00:00:56,640
발전해 왔는지 그 핵심을 함께 따라가 보시죠. 여러분이 AI의 가능성을

13
00:00:56,640 --> 00:01:01,719
이해하는데 꼭 필요한 내용만 뽑아보겠습니다. 그럼 가장 기본적이면서도

14
00:01:01,719 --> 00:01:06,359
중요한 발견이었던 연세적 사고 코오티 이부터 시작해 볼까요. 이게

15
00:01:06,359 --> 00:01:11,640
구글 리서치의 웨이 등이 2022년에 발표한 거죠. 네. 맞아요. 핵심

16
00:01:11,640 --> 00:01:16,599
은 그거였죠. AI한테 니 생각 과정을 단계별로 설명해봐 이렇게

17
00:01:16,599 --> 00:01:21,400
시키는 것만으로도 출원 능력이 확 좋아진다는 거. 와 정말 간단한

18
00:01:21,400 --> 00:01:27,240
아이디어 같은데 효과가 코콘요. 네. 마치 우리가 수학 문제 풀 때

19
00:01:27,240 --> 00:01:32,840
프리 과정을 쭉 적으면 더 정확해지잖아요. 그거랑 비슷해요. LLM이 문제

20
00:01:32,840 --> 00:01:37,040
해결 과정을 하나하나 생성하도록 유도하는 방식이죠. 특히 큰 모델

21
00:01:37,040 --> 00:01:42,280
에서 효과가 좋았다고요. 네. 파임 540비 같은 대규모 모델에서

22
00:01:42,280 --> 00:01:47,680
그 수학 문제 벤치마크인 GSM8K 성능 을 크게 높였어요. 그리고 좋은

23
00:01:47,680 --> 00:01:52,360
점은 모델을 따고 튜닝 을 필요 없이 프롬프트의 예심 몇 개만 넣어져도

24
00:01:52,360 --> 00:01:56,560
효과가 있다는 거. 되게 실용적이네요. 그렇죠. 그런데 이제

25
00:01:56,560 --> 00:02:01,840
위등 연구에서도 지적했듯이 완벽하진 않아요. 계산실수나 기호 오류

26
00:02:01,840 --> 00:02:06,760
같은 것도 있지만 문제 자체를 잘못 이해하는 그런 의미론적 오류도

27
00:02:06,760 --> 00:02:11,400
절반 이상 나왔고요. 아 54%나 됐다고 했죠. 모델이 커져도 그건

28
00:02:11,400 --> 00:02:16,719
여전하군요. 네. 그리고 또 그 위등의 후속연구에서도 지적하는데

29
00:02:16,719 --> 00:02:21,039
출온 가정에 막 너무 길어지고 좀 불필요하게 장황해질 수도 있다는

30
00:02:21,039 --> 00:02:25,520
그런 한계점도 있고요. 그렇군요. 코티가 이렇게 한 갤로 쭉

31
00:02:25,520 --> 00:02:29,639
가는 방식이라면 좀 더 복잡한 문제 에서는 여러 가능성을 동시에

32
00:02:29,639 --> 00:02:33,740
생각해보는 게 더 낮지 않을까요. 바로 그겁니다. 거기서 출발한

33
00:02:33,740 --> 00:02:40,879
게 생각의 틀이 TOT 방식이에요. 2023년에 야우 등이 처음 재환했고 최근이죠.

34
00:02:40,879 --> 00:02:47,159
2024년에 홍콩 중룸대랑 화회의 노아의 방주 랩에 위등이 이걸 강화학습

35
00:02:47,159 --> 00:02:53,359
이란 결합한 TOT 아래 연구를 내놨습니다. 아 TOT 이름 그대로 여러 생각의

36
00:02:53,359 --> 00:02:58,479
가지를 만들어 보는 거군요. 네. 여러 출온 경로 그러니까 생각의

37
00:02:58,479 --> 00:03:04,319
가지를 동시에 탐색하고 평가하면서 제일 좋은 답을 찾아가는 방식이에요.

38
00:03:04,319 --> 00:03:08,960
마치 우리가 채스 둘 때나 수도쿠 퍼즐 볼 때 여러 수를 미리 보고 제일

39
00:03:08,960 --> 00:03:12,960
괜찮은 걸 고르는 것처럼요. 그러면 코티처럼 일단 가보고 아 이거

40
00:03:12,960 --> 00:03:16,760
아니네 하는 게 아니라 미리 여러 개를 비교해서 별로인 건 버릴 수도

41
00:03:16,760 --> 00:03:21,760
있겠네요. 효율적이겠는데요. 정확해요. 가능성이 낮아 보이는 경로

42
00:03:21,760 --> 00:03:26,040
는 미리 가지치기를 하는 거죠. 그럼 계산자원을 아퀴수 있고요.

43
00:03:26,040 --> 00:03:31,520
우등의 연구를 보면 그 TOT Q&A P 모델로 수도쿠 같은 퍼즈를 풀 때

44
00:03:31,520 --> 00:03:37,200
기존 코어티 방식보다 훨씬 적은 톡은 그러니까 생각 예산으로도 더 높은

45
00:03:37,199 --> 00:03:42,359
성능을 냈다고요. 훨씬 적은 자원으로요. 네. 그래서 여러 제약 조건

46
00:03:42,359 --> 00:03:47,000
있는 상황에서 최저게 계획을 세우는 문제에 특히 강점을 볼 수 있을 것

47
00:03:47,000 --> 00:03:51,479
것 같아요. 그런데 그럼 또 어떤 기준으로 경로를 탐색하고 평가할

48
00:03:51,479 --> 00:03:56,679
지 그 전략 자체를 정하는 게 또 복잡한 문제가 될 수도 있겠네요.

49
00:03:56,679 --> 00:04:02,079
맞아요. 그 부분이 또 연구가 필요한 지점이죠. 자 TOT이도 흥미로운데

50
00:04:02,079 --> 00:04:06,839
여전히 이건 언어라는 틀 안에서 움직이는 거잖아요. 그렇죠. 생각의 과정을

51
00:04:06,840 --> 00:04:12,120
언어로 표현하니까요. 그런데 AI가 꼭 우리처럼 단어로만 생각해할까요?

52
00:04:12,120 --> 00:04:16,800
이 질문에서 출발한 어떻게 보면 더 과감한 적근법이 있는 것 같아요.

53
00:04:16,800 --> 00:04:21,840
바로 코코넛 연속적 사구의 사슬입니다. 네. 드디어 코코넛 얘기

54
00:04:21,840 --> 00:04:27,680
네요. 이게 올해 2024년 발표된 연구인데 이름도 그렇고 아이디어도 상당히

55
00:04:27,680 --> 00:04:32,519
신선합니다. 사실 이건 인간 내에 연구, 특히 신경과학 연구에서

56
00:04:32,519 --> 00:04:37,319
영감을 받았어요. 우리가 복잡한 생각을 할 때 꼭 언어 영역만 횟송

57
00:04:37,319 --> 00:04:42,060
화되는 건 아니거든요. 아 그래요 다른 영역도 같이 쓰나요. 네. 수학적

58
00:04:42,060 --> 00:04:46,319
사고 같은 걸 할 때는 다른 영역이 더 횟송화된다는 연구들이 있죠.

59
00:04:46,319 --> 00:04:50,759
코코넛의 회심 아이디어는 여기서 출발해요. LLM이 출온 단계를 생성할 때

60
00:04:50,759 --> 00:04:54,879
굳이 이걸 단어로 바꾸는 과정을 건너띠자는 겁니다. 단어 변환을

61
00:04:54,879 --> 00:04:59,759
건너띠인다고요? 그럼 뭘로. 네 부에 숨겨진 상태, 히든스테이트

62
00:04:59,759 --> 00:05:04,699
벡터를 쓰는 거예요. 이게 뭐냐면 단어의 의미나 문맥을 압축적으로 담고

63
00:05:04,699 --> 00:05:08,819
있는 숫자들의 묶음 뭐 그런 건데요. 이걸 다음 단계 입력으로 그냥

64
00:05:08,819 --> 00:05:14,079
바로 쓰는 거죠. 와 그러니까 단어대신 의미가 담긴 그 숫자 덩어리로

65
00:05:14,079 --> 00:05:18,240
바로 생각이 고리를 이어간다는 거네요. 네 맞습니다. 그게 어떤 장점이

66
00:05:18,240 --> 00:05:23,680
있는 건가요. 가장 큰 장점은요. 전체 출온 과정이 수학적으로 미분

67
00:05:23,680 --> 00:05:28,360
가능해진다는 거예요. 미분 가능 이요. 그게 왜 중요하죠?

68
00:05:28,360 --> 00:05:33,860
그 덕분에 그리에 디센트라는 AI 학습의 표준적인 방법을 쓸 수

69
00:05:33,860 --> 00:05:39,520
있게 돼요. AI가 정답에 더 가까워지도록 전체 출온 과정을 통째로

70
00:05:39,520 --> 00:05:43,280
최적화할 수 있는 거죠. 어느 단계가 중간에 기면 이게 좀 어려웠

71
00:05:43,280 --> 00:05:47,920
거든요. 아 최적화가 훨씬 용이해지는군요. 그렇죠.

72
00:05:47,920 --> 00:05:52,800
그런데 물론 처음부터 이런 잠재 공간 그러니까 단어가 아닌 추상적인

73
00:05:52,800 --> 00:05:57,400
의미 공간에서 출온을 배우기 하는 건 좀 어려워요. 네 그럴 것 같아요.

74
00:05:58,399 --> 00:06:05,199
그래서 초기에는 언어기반 코오티 로 약간 길잡이어카를 해주고 점진적으로

75
00:06:05,199 --> 00:06:09,359
그 언어 단계를 없애나가는 커리클럼 학습 방식을 썼다고 해요.

76
00:06:09,359 --> 00:06:13,560
I-C-O-T 라고 부르던데요. 아 단계적으로 가르치는 거군요.

77
00:06:13,560 --> 00:06:18,599
네. GPT2 모델로 실험했는데 이 커리클럼 학습이 꼭 필요했다고

78
00:06:18,599 --> 00:06:24,719
하고요. 더 흥미로운 건 이렇게 학습된 모델이 그 잠재 공간 안에서 스스로

79
00:06:24,720 --> 00:06:30,200
여러 경로를 탐색하고 가치를 평가하고 불필요한 경로는 제거하는

80
00:06:30,200 --> 00:06:35,360
모습을 보였다는 거예요. 오 그거 마치 TOT랑 비슷하지 않나요. 맞아요.

81
00:06:35,360 --> 00:06:40,520
언어를 쓰지 않는데도 마치 TOT처럼 잠재적 탐색트리 같은 걸 스스로

82
00:06:40,520 --> 00:06:45,960
구축해서 효율적인 탐색을 하더라고요. 와 정말 신기하네요. 언어

83
00:06:45,960 --> 00:06:51,040
없이도 그런 구조를 만들어냈는다니. 그럼 정리를 좀 해보면 AI 출온

84
00:06:51,040 --> 00:06:56,680
방식이 처음에는 언어로 단계를 설명하는 코티에서 시작해서 여러 언어

85
00:06:56,680 --> 00:07:02,680
조 가능성을 탐색하는 TOT로 발전하고 이제는 아예 언어를 넘어서는 잠재

86
00:07:02,680 --> 00:07:07,120
공간에서 직접 출연하는 코코넛으로까지 지나하고 있는 거군요.

87
00:07:07,120 --> 00:07:11,759
네. 그렇게 볼 수 있겠습니다. 물론 각 방식이 완전히 대체된다기보다는

88
00:07:11,759 --> 00:07:15,320
문제의 종류나 필요에 따라 다른 방식이 더 유용할 수 있겠죠.

89
00:07:15,320 --> 00:07:20,720
자 그럼 이 모든 발전이 지금 듣고 계신 당신에게는 어떤 의미가 있을까요.

90
00:07:20,720 --> 00:07:25,840
네 이게 그냥 학문적인 이야기로 끝나는 게 아니죠. 여러분이 실제로 AI를

91
00:07:25,840 --> 00:07:30,160
어떻게 활용할지에 직접적인 영향을 줄 수 있습니다. 예를 들면요.

92
00:07:30,160 --> 00:07:35,240
가령 간단한 문제 해결에는 코티 프롬특만으로도 충분할 수 있어요.

93
00:07:35,240 --> 00:07:39,600
구현이 비교적 쉽고요. 하지만 큰 모델이 필요하고 아까 말했듯

94
00:07:39,600 --> 00:07:44,360
오류가능성도 있죠. 네 그렇죠. 반면에 좀 더 복잡한 계획이나 탐색이

95
00:07:44,360 --> 00:07:49,080
필요한 문제라면 TOT 접근법이 더 효율적일 수 있습니다. 여러 가능성을

96
00:07:49,079 --> 00:07:51,959
책의적으로 따져보니까요. 그리고 코코넛은요?

97
00:07:51,959 --> 00:07:57,959
코코넛은 아직 초기 연구 단계고 말씀드렸듯 특별한 학습 과정이 필요하긴 해요.

98
00:07:57,959 --> 00:08:02,639
하지만 언어에 한계를 넘어설했을 수 있는 더 깊고 유연한 출용의 가능성을

99
00:08:02,639 --> 00:08:04,439
보여준다는 점에서 의미가 큽니다.

100
00:08:04,439 --> 00:08:05,439
그렇군요.

101
00:08:05,439 --> 00:08:11,099
그래서 앞으로 AI 도구를 쓰실 때 아 이 AI는 어떤 출원 방식을 기반으로

102
00:08:11,099 --> 00:08:15,639
하겠구나 그래서 어떤 장단점이 있겠구나 이걸 이해하는 게 여러분의

103
00:08:15,639 --> 00:08:19,240
문제 해결 능력을 한 단계도 높이는 데 분명 도움이 될 겁니다.

104
00:08:19,240 --> 00:08:24,539
오늘 AI가 생각하는 다양한 방식 특히 언어에 틀을 벗어나려는 코코넛의

105
00:08:24,539 --> 00:08:27,879
시도는 정말 많은 생각을 하게 만드는 것 같습니다.

106
00:08:27,879 --> 00:08:32,139
네 상당히 도발적인 아이디어죠. 만약 AI가 우리가 쓰는 그런 언어적

107
00:08:32,139 --> 00:08:37,559
표현 없이도 효과적으로 문제를 풀 수 있다면 그건 AI 자체의 발전을 넘어서

108
00:08:37,559 --> 00:08:42,039
어쩌면 우리 인간에 사고란 과연 무엇인지에 대해서도 다시 질문하게

109
00:08:42,039 --> 00:08:44,039
만드는 것 같아요.

110
00:08:44,039 --> 00:08:47,399
생각과 언어래 관계에 대한 근본적인 질문을 던지게 되죠.

111
00:08:47,399 --> 00:08:51,539
미래의 AI는 정말 우리가 지금 상상하는 것과는 전혀 다른 방식으로

112
00:08:51,539 --> 00:08:55,559
사고 하게 될까요. 이 흥미로운 질문을 당신도 한번 곱 씹어보시는

113
00:08:55,559 --> 00:09:00,279
건 어떨까요. 오늘도 바이트비트 마인드 캐스토와 함께 AI의 흐미로운

114
00:09:00,279 --> 00:09:02,919
세계를 탐험해 주셔서 감사합니다.

115
00:09:02,919 --> 00:09:06,120
다음 에피소드에서 더욱 흥미로운 주제로 다시 찾아뵙겠습니다.

