from typing import Dict, Any, List
import ast
import operator
from langchain.tools import tool
from src.models import ModelManager

class ToolManager:
    """ë„êµ¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model_manager: ModelManager):
        self.model_manager = model_manager
        self.tools: List[Any] = []
        self._initialize_tools()
    
    def _initialize_tools(self):
        """ë„êµ¬ë“¤ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.tools = [
            self._create_safe_calculator(),
            self._create_perplexity_search(),
            self._create_text_analyzer(),
            self._create_model_selector()
        ]
    
    @staticmethod
    def _create_safe_calculator():
        @tool
        def safe_calculator(expression: str) -> str:
            """ì•ˆì „í•œ ìˆ˜í•™ ê³„ì‚°ê¸° - ê¸°ë³¸ ì‚°ìˆ  ì—°ì‚°ë§Œ ì§€ì›í•©ë‹ˆë‹¤.
            
            Args:
                expression: ê³„ì‚°í•  ìˆ˜ì‹ (ì˜ˆ: "2 + 3 * 4")
            
            Returns:
                str: ê³„ì‚° ê²°ê³¼ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
            """
            try:
                allowed_operators = {
                    ast.Add: operator.add,
                    ast.Sub: operator.sub,
                    ast.Mult: operator.mul,
                    ast.Div: operator.truediv,
                    ast.Pow: operator.pow,
                    ast.USub: operator.neg,
                    ast.UAdd: operator.pos,
                    ast.Mod: operator.mod,
                }
                
                def eval_node(node):
                    if isinstance(node, ast.Constant):
                        return node.value
                    elif isinstance(node, ast.BinOp):
                        left = eval_node(node.left)
                        right = eval_node(node.right)
                        if isinstance(node.op, ast.Div) and right == 0:
                            raise ValueError("0ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        return allowed_operators[type(node.op)](left, right)
                    elif isinstance(node, ast.UnaryOp):
                        operand = eval_node(node.operand)
                        return allowed_operators[type(node.op)](operand)
                    else:
                        raise ValueError(f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì—°ì‚°: {type(node).__name__}")
                
                tree = ast.parse(expression, mode='eval')
                result = eval_node(tree.body)
                return f"ğŸ’¡ ê³„ì‚° ê²°ê³¼: {result}"
                
            except Exception as e:
                return f"âŒ ê³„ì‚° ì˜¤ë¥˜: {str(e)}"
        
        return safe_calculator
    
    def _create_perplexity_search(self):
        @tool
        def perplexity_search(query: str) -> str:
            """Perplexityë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ ì›¹ ê²€ìƒ‰ ë° ì •ë³´ ì¡°íšŒ
            
            Args:
                query: ê²€ìƒ‰í•  ì§ˆë¬¸ì´ë‚˜ í‚¤ì›Œë“œ
            
            Returns:
                str: ê²€ìƒ‰ ê²°ê³¼ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
            """
            try:
                model = self.model_manager.get_model("perplexity")
                if not model:
                    return "âŒ Perplexity ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                
                search_prompt = f"""You are a helpful AI assistant. Please provide a detailed and accurate response to the following query:

Query: {query}

Please follow these guidelines:
1. Provide factual and up-to-date information
2. Include relevant statistics or data when available
3. Cite reliable sources
4. Keep the response clear and well-structured
5. If the query is in Korean, respond in Korean; if in English, respond in English

Response:"""
                
                response = model.invoke(search_prompt)
                return f"ğŸ” ê²€ìƒ‰ ê²°ê³¼:\n{response.content}"
                
            except Exception as e:
                return f"âŒ ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}"
        
        return perplexity_search
    
    @staticmethod
    def _create_text_analyzer():
        @tool
        def text_analyzer(text: str) -> str:
            """í…ìŠ¤íŠ¸ ë¶„ì„ ë„êµ¬ - ë‹¨ì–´ ìˆ˜, ë¬¸ì ìˆ˜, ê°ì • ë¶„ì„ ë“±
            
            Args:
                text: ë¶„ì„í•  í…ìŠ¤íŠ¸
            
            Returns:
                str: ë¶„ì„ ê²°ê³¼
            """
            try:
                words = text.split()
                word_count = len(words)
                char_count = len(text)
                char_count_no_spaces = len(text.replace(' ', ''))
                sentence_count = text.count('.') + text.count('!') + text.count('?')
                
                korean_chars = sum(1 for c in text if '\uac00' <= c <= '\ud7af')
                english_chars = sum(1 for c in text if c.isalpha() and ord(c) < 128)
                
                if korean_chars > english_chars:
                    primary_language = "í•œêµ­ì–´"
                elif english_chars > korean_chars:
                    primary_language = "ì˜ì–´"
                else:
                    primary_language = "í˜¼í•©/ê¸°íƒ€"
                
                avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
                
                result = f"""ğŸ“Š í…ìŠ¤íŠ¸ ë¶„ì„ ê²°ê³¼:
                
ğŸ“ ê¸°ë³¸ í†µê³„:
   â€¢ ë‹¨ì–´ ìˆ˜: {word_count:,}ê°œ
   â€¢ ì „ì²´ ë¬¸ì ìˆ˜: {char_count:,}ì
   â€¢ ê³µë°± ì œì™¸ ë¬¸ì ìˆ˜: {char_count_no_spaces:,}ì
   â€¢ ë¬¸ì¥ ìˆ˜: {sentence_count}ê°œ
   â€¢ í‰ê·  ë‹¨ì–´ ê¸¸ì´: {avg_word_length:.1f}ì
   
ğŸŒ ì–¸ì–´ ì •ë³´:
   â€¢ ì£¼ìš” ì–¸ì–´: {primary_language}
   â€¢ í•œê¸€ ë¬¸ì: {korean_chars}ì
   â€¢ ì˜ë¬¸ ë¬¸ì: {english_chars}ì
   
ğŸ“ˆ ì½ê¸° ì •ë³´:
   â€¢ ì˜ˆìƒ ì½ê¸° ì‹œê°„: {word_count / 200:.1f}ë¶„ (ë¶„ë‹¹ 200ë‹¨ì–´ ê¸°ì¤€)"""
                
                return result
                
            except Exception as e:
                return f"âŒ ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
        
        return text_analyzer
    
    def _create_model_selector(self):
        @tool
        def model_selector(task: str, preferred_model: str = "openai") -> str:
            """íŠ¹ì • AI ëª¨ë¸ì—ê²Œ ì‘ì—…ì„ í• ë‹¹í•©ë‹ˆë‹¤.
            
            Args:
                task: ìˆ˜í–‰í•  ì‘ì—…ì´ë‚˜ ì§ˆë¬¸
                preferred_model: ì‚¬ìš©í•  ëª¨ë¸ (openai, gemini, perplexity, ollama)
            
            Returns:
                str: ëª¨ë¸ì˜ ì‘ë‹µ ê²°ê³¼
            """
            try:
                available_models = list(self.model_manager.models.keys())
                
                if preferred_model not in available_models:
                    return f"âŒ ëª¨ë¸ '{preferred_model}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {', '.join(available_models)}"
                
                model = self.model_manager.get_model(preferred_model)
                
                model_prompts = {
                    "openai": f"OpenAI GPT ëª¨ë¸ë¡œì„œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:\n\n{task}",
                    "gemini": f"Google Gemini ëª¨ë¸ë¡œì„œ ì°½ì˜ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:\n\n{task}",
                    "perplexity": f"ìµœì‹  ì •ë³´ì™€ í•¨ê»˜ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”:\n\n{task}",
                    "ollama": f"ë¡œì»¬ AI ëª¨ë¸ë¡œì„œ ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”:\n\n{task}"
                }
                
                prompt = model_prompts.get(preferred_model, task)
                response = model.invoke(prompt)
                
                return f"ğŸ¤– [{preferred_model.upper()} ì‘ë‹µ]:\n{response.content}"
                
            except Exception as e:
                return f"âŒ ëª¨ë¸ í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"
        
        return model_selector
    
    def get_tools(self) -> List[Any]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return self.tools
    
    def get_tool_names(self) -> List[str]:
        """ë„êµ¬ ì´ë¦„ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return [tool.name for tool in self.tools] 